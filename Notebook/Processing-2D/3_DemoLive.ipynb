{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d2e623e",
   "metadata": {
    "id": "5d2e623e"
   },
   "source": [
    "# Progetto DSIM - Demo Live Immagini\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "Autori: Ginevra Mariani | Lorenzo Mora | Confalonieri Riccardo <br>\n",
    "E-mail: g.mariani34@campus.unimib.it, l.mora4@campus.unimib.it, r.confalonieri5@campus.unimib.it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611ef8ca",
   "metadata": {
    "id": "611ef8ca"
   },
   "source": [
    "Lo scopo di questo notebook è implementare una live demo per dimostrare l'efficacia dei modelli implementati per il task di face recognition. Siccome la demo necessita della telecamera per acquisire le immagini è necessario eseguire il file localmente e non in Colab! Inoltre è importante controllare il path da cui si caricano i modelli trainati per evitare errori. <br>\n",
    "\n",
    "**DISCLAIMER:** Nella finestra viene riportata anche la probabilità rispetto alla predizione del modello. Questo è valido soltanto sotto l'ipotesi di \"mondo chiuso\", ovvero se si considera che al modello non verranno mai forniti volti al di fuori di quelli del gruppo. Altrimenti questa probabilità non avrebbe alcun senso, e nel caso si volesse mantenerla sarebbe necessario riaddestrare i modelli per prevedere anche una classe \"unknown\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101da570",
   "metadata": {
    "id": "101da570"
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220ec5e0",
   "metadata": {
    "id": "220ec5e0"
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "# per gestire lo scatto della foto dal video\n",
    "from cv2 import VideoCapture\n",
    "# per caricare il modello CNN\n",
    "from tensorflow import keras\n",
    "# per pulire output console\n",
    "from IPython.display import clear_output\n",
    "# per operazioni con array\n",
    "import numpy as np\n",
    "import os # per gestire i path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587627a9",
   "metadata": {
    "id": "587627a9"
   },
   "source": [
    "## Demo\n",
    "In questa demo viene visualizzata una finestra con le immagini catturate in real time attraverso la webcam principale del pc. A partire da queste immagini viene applicato il face detector di openCV, se viene trovato un volto il suo crop viene passato al modello per effettuare la predizione. <br>\n",
    "Il risultato viene quindi visualizzato a video come testo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54469245",
   "metadata": {
    "id": "54469245"
   },
   "outputs": [],
   "source": [
    "def start_demo(face_detector, model, dict_names):\n",
    "    \"\"\"\n",
    "    Visualizza una finestra con la riproduzione streaming catturata dalla camera principale\n",
    "    del pc. Ad ogni frame viene quindi applicato il face detector e, se presente un volto,\n",
    "    quest'ultimo viene passato al modello per riconoscere la persona.\n",
    "    \n",
    "    :param cv2.CascadeClassifier face_detector: Detector per il riconoscimento del volto\n",
    "    :param keras.engine.functional.Functional model: Modello keras per la predizione\n",
    "    :param str{} dict_names: Dizionario che associa nomi e numeri\n",
    "    \"\"\"\n",
    "        \n",
    "    # nel caso ci siano errori chiudo la finestra in automatico\n",
    "    try:\n",
    "        # initialize the camera\n",
    "        cam = VideoCapture(0)\n",
    "\n",
    "        while True:\n",
    "            # acquisisco l'immagine dalla cam\n",
    "            s, frame = cam.read()\n",
    "            \n",
    "            # se l'acquisizione non è andata a buon fine interrompo\n",
    "            if not s:\n",
    "                break\n",
    "            else:\n",
    "                # converto l'immagine in b/n\n",
    "                img_bw = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "                \n",
    "                # applico il face detector sull'immagine in b/n\n",
    "                faces = face_detector.detectMultiScale(img_bw, 1.1, 8)\n",
    "\n",
    "                for (x,y,w,h) in faces:\n",
    "                    # visualizzo il rettangolo di detection\n",
    "                    cv.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "                    \n",
    "                    # estraggo il crop\n",
    "                    crop = frame[y:y+h, x:x+w]\n",
    "                    # converto il crop a colori RGB\n",
    "                    crop = cv.cvtColor(crop, cv.COLOR_BGR2RGB)\n",
    "                    # riscalo il crop in 224x224\n",
    "                    crop = cv.resize(crop, (224, 224)) \n",
    "                    # aggiungo una dimensione\n",
    "                    crop = np.expand_dims(crop, axis = 0)\n",
    "                     \n",
    "                    # applico il modello al crop\n",
    "                    y_pred = model.predict(crop)\n",
    "                    \n",
    "                    # estraggo la predizione migliore\n",
    "                    y_pred_max = np.argmax(y_pred)\n",
    "                    \n",
    "                    # ottengo la probabilità della previsione\n",
    "                    y_pred = y_pred[0][y_pred_max]\n",
    "                    \n",
    "                    # se il modello predice con probabilità inferiore allora è incerto e quindi non visualizzo il testo\n",
    "                    if y_pred > 0.6:\n",
    "                        # visualizzo la previsione\n",
    "                        cv.putText(frame, \n",
    "                               (\"Person: \" + str(dict_names[y_pred_max])) + ' - ' + str(np.round(y_pred,3)), \n",
    "                               ((x, y-5)), \n",
    "                                cv.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "                    \n",
    "            \n",
    "            # visualizzo la finestra\n",
    "            cv.imshow('FaceRecognition', frame)\n",
    "\n",
    "            # Termino il ciclo se viene premuto Q\n",
    "            if cv.waitKey(20) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        # rilascio la cam e chiudo la finestra se il ciclo è finito\n",
    "        cam.release()\n",
    "        cv.destroyAllWindows()\n",
    "        \n",
    "    except: # rilascio la cam e chiudo la finestra\n",
    "        cam.release()\n",
    "        cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627fcd84",
   "metadata": {
    "id": "627fcd84"
   },
   "outputs": [],
   "source": [
    "# carico il modello di face detection pre-addestrato\n",
    "face_detector = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "# carico il modello pre-trainato\n",
    "#model = keras.models.load_model('./mobilenet.h5')\n",
    "model = keras.models.load_model('./vggface.h5')\n",
    "\n",
    "# definisco un dizionario con l'associazione Label-Nome\n",
    "dict_name = {0: 'Ginevra', 1: 'Lorenzo', 2: 'Riccardo'}\n",
    "start_demo(face_detector, model, dict_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce15bcb",
   "metadata": {
    "id": "9ce15bcb"
   },
   "source": [
    "## Considerazioni finali\n",
    "L'accuracy della previsione dipende fortemente dal modello utilizzato ma anche dal detector, in alcuni casi infatti si è notato che opencv rileva come volti anche oggetti o la semplice porzione dell'occhio. Queste problematiche possono essere risolte usando dei detector più validi come `dlib` che non si è riusciti però a implementare in locela in quanto richiede una GPU. <br>\n",
    "Inoltre un altro problema legato al detector è che ruotando il volto non riesce più ad individuare la faccia, in questo caso il modello non può quindi fornire una previsione. Facendo dei test croppando manualmente l'immagine si è però notato che il modello performa ugualmente anche con volti ruotati o inclinati. <br>\n",
    "Infine si è notato che in alcuni casi il frame risulta rallentato, questo è dovuto a molteplici motivi:\n",
    "\n",
    "* risorse hardware del pc\n",
    "* tempo necessario per la detection\n",
    "* tempo necessario per il recognition\n",
    "\n",
    "Per quanto riguarda le ultime due casistiche il tempo si ridurrebbe drasticamente utilizzando una GPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "C9dMot9E9KgP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1992,
     "status": "ok",
     "timestamp": 1644440535673,
     "user": {
      "displayName": "Riccardo Confalonieri",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05953771849724216239"
     },
     "user_tz": -60
    },
    "id": "C9dMot9E9KgP",
    "outputId": "77bb71c9-485f-4c24-b39e-8fd6a0f6703b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook /content/drive/MyDrive/Confalonieri_Mariani_Mora_DSIM/Notebook/Processing-2D/3_DemoLive.ipynb to html\n",
      "[NbConvertApp] Writing 292439 bytes to /content/drive/MyDrive/Confalonieri_Mariani_Mora_DSIM/Notebook/Processing-2D/3_DemoLive.html\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download notebook in .html extension\n",
    "%%shell\n",
    "jupyter nbconvert --to html '/content/drive/MyDrive/Confalonieri_Mariani_Mora_DSIM/Notebook/Processing-2D/3_DemoLive.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n5iWL2vh9T2r",
   "metadata": {
    "id": "n5iWL2vh9T2r"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3_DemoLive.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
